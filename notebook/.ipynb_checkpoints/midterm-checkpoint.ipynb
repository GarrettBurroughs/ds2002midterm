{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87685a01",
   "metadata": {},
   "source": [
    "# Data Setup Script\n",
    "\n",
    "This script is meant to create the initial \"data sources\" for the DS 2002 midterm. Because this project requires data to be pulled from different sources that don't yet exist, this script generates json files that can be served either from the filesystem or api endpoints, as well as be uploaded to mongodb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bef61d",
   "metadata": {},
   "source": [
    "### Libraires\n",
    "We first have to import the required libraries to manipulate the data\n",
    "\n",
    "**Note:** If libraries are not yet installed run `pip install -r requirements.txt` from the parent directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "330c3eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "import pymongo\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08768197",
   "metadata": {},
   "source": [
    "### Set up connection details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "641391fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Maybe you meant '==' or ':=' instead of '='? (4200135168.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_11645/4200135168.py\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    mongodb = {}\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Maybe you meant '==' or ':=' instead of '='?\n"
     ]
    }
   ],
   "source": [
    "mysql_uid = \"root\"\n",
    "mysql_pwd = \"Passw0rd123\"\n",
    "\n",
    "atlas_cluster_name = \"cluster0.q0atcnd\"\n",
    "atlas_user_name = \"gab8un\"\n",
    "atlas_password = \"XwlxqfpWD8PxodaA\"\n",
    "\n",
    "mongo_connections = {\n",
    "    \"local\": f\"mongodb://localhost:27017/\",\n",
    "    \"atlas\": f\"mongodb+srv://{atlas_user_name}:{atlas_password}@{atlas_cluster_name}.mongodb.net\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ca6935",
   "metadata": {},
   "source": [
    "### Create functions to interact with SQL and Mongodb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9bbb917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sql_dataframe(user_id, pwd, db_name, sql_query):\n",
    "    '''Create a connection to the MySQL database'''\n",
    "    conn_str = f\"mysql+pymysql://{user_id}:{pwd}@localhost/{db_name}\"\n",
    "    sqlEngine = create_engine(conn_str, pool_recycle=3600)\n",
    "    \n",
    "    '''Invoke the pd.read_sql() function to query the database, and fill a Pandas DataFrame.'''\n",
    "    conn = sqlEngine.connect()\n",
    "    dframe = pd.read_sql(sql_query, conn);\n",
    "    conn.close()\n",
    "    \n",
    "    return dframe\n",
    "\n",
    "\n",
    "def get_mongo_dataframe(connect_str, db_name, collection, query):\n",
    "    '''Create a connection to MongoDB'''\n",
    "    client = pymongo.MongoClient(connect_str)\n",
    "    \n",
    "    '''Query MongoDB, and fill a python list with documents to create a DataFrame'''\n",
    "    db = client[db_name]\n",
    "    dframe = pd.DataFrame(list(db[collection].find(query)))\n",
    "    dframe.drop(['_id'], axis=1, inplace=True)\n",
    "    client.close()\n",
    "    return dframe\n",
    "\n",
    "\n",
    "def set_dataframe(user_id, pwd, db_name, df, table_name, pk_column, db_operation):\n",
    "    '''Create a connection to the MySQL database'''\n",
    "    conn_str = f\"mysql+pymysql://{user_id}:{pwd}@localhost/{db_name}\"\n",
    "    sqlEngine = create_engine(conn_str, pool_recycle=3600)\n",
    "    connection = sqlEngine.connect()\n",
    "    \n",
    "    '''Invoke the Pandas DataFrame .to_sql( ) function to either create, or append to, a table'''\n",
    "    if db_operation == \"insert\":\n",
    "        df.to_sql(table_name, con=connection, index=False, if_exists='replace')\n",
    "        connection.execute(f\"ALTER TABLE {table_name} ADD PRIMARY KEY ({pk_column});\")\n",
    "            \n",
    "    elif db_operation == \"update\":\n",
    "        df.to_sql(table_name, con=connection, index=False, if_exists='append')\n",
    "    \n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbff6a3b",
   "metadata": {},
   "source": [
    "### Load Data into database\n",
    "The database files are stored in the notebooks directory, and are loaded to populate the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0d92ba6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './sakila-db/sakila-schem.sql'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11645/1479702616.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msakila_schema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./sakila-db/sakila-schem.sql'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msakila_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./sakila-db/sakila-schem.sql'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msakila_schema_sql\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msakila_schema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msakila_data_sql\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msakila_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './sakila-db/sakila-schem.sql'"
     ]
    }
   ],
   "source": [
    "sakila_schema = open(\n",
    "    os.path.join(os.getcwd, 'sakila-db/sakila-schema.sql')\n",
    ")\n",
    "sakila_data = open(\n",
    "    os.path.join(os.getcwd, 'sakila-db/sakila-data.sql')\n",
    ")\n",
    "\n",
    "sakila_schema_sql = sakila_schema.read()\n",
    "sakila_data_sql = sakila_data.read()\n",
    "print(sakila_schema_sql)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e1112f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
